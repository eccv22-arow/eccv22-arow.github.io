<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <title>ECCV 2022 Workshop on Adversarial Robustness in the Real World</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
    <link href="css/style.css" rel="stylesheet" type="text/css"/>
</head>

<body>

<div class="container">
<!--    <table border="0" align="center">
        <tr>
            <td width="700" align="center" valign="middle"><h3>ECCV 2020 Workshop on </h3>
                <span class="title"><strong>Adversarial Robustness in the Real World
</strong></span></td>
        </tr>
        <tr>
            <td colspan="3" align="center"><h3>Glasgow, Scotland<br>8:45am - 7:00pm (UTC+1) on August 23rd, 2020</h3></td>
        </tr>
    </table>-->
    <p><img src="figures/opening-2.png" width="1000" align="middle"/></p>
    <br>
<!--     <h2><a href="https://www.youtube.com/watch?v=lDptIbsMIE0&list=PLWqw4ACzC-1XnyywVl53wc7lEOzSyhHYM">[Video Recording]</a></h2>-->
<!--     <h2><a href="https://docs.google.com/presentation/d/1PKI7Wf8QiW6cb_T3hjwe2wcEw3PtMujCBI6crZa99AE/edit?usp=sharing" target="_blank">[Join Instruction]</a></h2>
    <h2><a href="https://www.facebook.com/2016490571858823/videos/1498926407141264" target="_blank">[Facebook Live]</a></h2> -->
</div>

</br>

<div class="container">
    <h2>Overview</h2>
    <div class="overview">
        <p>
            Recent deep-learning-based methods achieve great performance on various vision applications. However, insufficient robustness on adversarial cases limits real-world applications of deep-learning-based methods. AROW workshop aims to explore adversarial examples, as well as, evaluate and improve the adversarial robustness of computer vision systems.
        <p>
            This AROW workshop will be <strong>fully virtual</strong>.
        <br><br>

        Topics of AROW workshop include but are not limited to: 
        <h3><p><font color="blue"><li>Improving model robustness against unrestricted adversarial attacks</li></font></p></h3>
        <h3><p><font color="blue"><li>Improving generalization to out-of-distribution samples or unforeseen adversaries</li></font></p></h3>
        <h3><p><font color="blue"><li>Discovery of real-world adversarial examples</li></font></p></h3>
        <h3><p><font color="blue"><li>Novel architectures with robustness to occlusion, viewpoint, and other real-world domain shifts</li></font></p></h3>
        <h3><p><font color="blue"><li>Domain adaptation techniques for robust vision in the real world</li></font></p></h3>
        <h3><p><font color="blue"><li>Datasets for evaluating model robustness</li></font></p></h3>
        <h3><p><font color="blue"><li>Structured deep models and explainable AI</li></font></p></h3>
        </div>
</div>
</br>

<!-- <div class="container">
    <h2>Prize</h2>
    <div class="overview">
        <p>
            The workshop is sponsored by the Open Philanthropy regranting program. The funding covers <strong><font color="red">three</font></strong> Best Paper Awards (<strong><font color="red">$10,000</font></strong> each, $30,000 in total).
The awarded papers should study model robustness to threats beyond small l_p perturbations (e.g., adversarially optimized fog and snow effects, adversarial patches, adversarial elastic distortions, new attacks, etc.). The best papers will research attacks with large budgets that are perceptible, and/or attacks with specifications that are not known beforehand and are unforeseen.   
        <p>
            The best paper awards will be announced in the workshop.
</div>
</div>
</br>

<div class="container">
    <h2>Submission</h2>
    <div class="overview">
        <p>
            <h3><p><strong>Submission format: </font></strong></h3>
        <p>
            Submissions need to be anonymized and follow the <a href="https://eccv2022.ecva.net/submission/call-for-papers/">ECCV 2022 Author Instructions</a>. The workshop considers two types of submissions: (1) Long Paper: Papers are limited to 14 pages excluding references and will be included in the official ECCV proceedings, Please use the <a href="https://drive.google.com/file/d/171-xo72Jx40cZ4qT20ZZsDDKXPIOWnss/view?usp=sharing">ECCV template</a> ; (2) Short Papers: Papers are limited to 4 pages  <font color="red"> including </font> references and will NOT be included in the official ECCV proceedings (does not count as double submission for most vision conferences). Please use the <a href="https://cvpr2022.thecvf.com/sites/default/files/2021-10/cvpr2022-author_kit-v1_1-1.zip">CVPR template</a> for the short papers.
        <p>
            <h3><p><strong>Camera Ready: </font></strong></h3>
        <p>
            <strong>Long papers</strong> will be published as ECCV workshop proceeding, please follow the instructions and formats of <a href="https://eccv2022.ecva.net/submission/call-for-papers/">ECCV camera ready</a>.
        <p>
            <strong>Short papers</strong> use the CVPR template (camera ready). Based on the submissions recieved, we decided change paper length limitations to 4 pages <font color="red"> exclude </font> references. 
        <p>
            We will evaluate accepted papers based on the <strong>camera ready</strong> version to decide the best paper awards.
        <p>
            <h3><p><strong>Submissions Website: </font></strong></h3>
            <p>
            <a href="https://cmt3.research.microsoft.com/AROW2022/Submission/Index">https://cmt3.research.microsoft.com/AROW2022/Submission/Index</a>
        <br><br>
            <h3><p><strong>Important dates:</font></strong></h3>
            <h3><p><li><font color="blue">Submission deadline: <del>August 1, 2022</del></font> <font color="red">August 8, 2022, 23:59 (Pacific Time)</font> </li></p></h3>
            <h3><p><li><font color="blue">Notification to authors: <del>August 12, 2022</del></font> <font color="red"> August 17, 2022 </font></li></p></h3>
            <h3><p><li><font color="blue">Camera-ready: <del>August 15, 2022</del> </font> <font color="red"> August 21, 2022, 23:59 (Pacific Time)</font></li></p></h3>
            <h3><p><li><font color="blue">Workshop: October 23, 2022</font></li></p></h3>
    </div>
</div>
</br> -->

<div class="container">
    <h2>Schedule</h2>
        <div class="overview">
            <p>Oct. 23, 2022. IST: Israel local time (UTC +2); PST: Pacific Standard Time (UTC -8) <strong> <a href="https://go-live-il.zoom.us/j/88497625302?pwd=QnJVME5hTXhFTXE3RWVGNys5Ykpidz09">Live</a> </strong>
            <h3><p><strong>Israel Morning Session</font></strong></h3>
            <li>PST 11:05pm-11:35pm; IST 9:05am-9:35am</li> 
            <p>Invited Talk: <strong>Cihang Xie - CNN vs Transformer: Which One is More Robust - <a href="https://go-live-il.zoom.us/j/88497625302?pwd=QnJVME5hTXhFTXE3RWVGNys5Ykpidz09">Live</a> </strong>
            <li>PST 11:35pm-12:05am; IST 9:35am-10:05am</li> 
            <p>Invited Talk: <strong>Olga Russakovsky - <a href="https://princeton.zoom.us/rec/share/JRGRbE775jXmGD_iyu0UuVmH3UsDMOPS7Ezdv4QMvg6e2L6Y7Btbh0HKrsHi7ai2.j-7gxSyZRH45BvYK">Trustworthy and trusted computer vision </a> </strong>
            <li>PST 12:05am-12:35am; IST 10:05am-10:35am</li>            
            <p> Invited Talk: <strong>Alan Yuille - <a href="https://drive.google.com/file/d/1pt37zGbwvZ96x_OapQ0ulAeMirFHaQOS/view?usp=sharing">Challenging Artificial Intellegence of Vision Algorithm to Achieve Human-Level Performance </a> </strong>
            <li>PST 12:35am-1:05am; IST 10:35am-11:05am</li>   
            <p>Invited Talk: <strong>Xue Lin - <a href="https://drive.google.com/file/d/1wjhgZzcBAs44RH_Kei1fVSWFfDkQZZjh/view?usp=sharing">Evaluation of Deep Learning Robustness and Reverse Engineering of Pertubations</a> </strong>
                    
            <h3><p><strong>Israel Afternoon Session</font></strong></h3>
            <li>PST 4:15am-5:00am; IST 2:15pm-3:00pm</li> 
            <p>Invited Talk: <strong>Hima Hlakkaraju - <a href="https://drive.google.com/drive/folders/1Jxmrwd8JJ8meDcUvT7eLzGK_3gHvKy3u?usp=sharing"> Bringing Order to Chaos: Probing the Disagreement Problem in Explainable AI </a> </strong>
            <li>PST 5:00am-5:45am; IST 3:00pm-3:45pm</li> 
            <p>Invited Talk: <strong>Pin-Yu Chen - Reprogramming Foundation Models with Limited Resources - <a href="https://go-live-il.zoom.us/j/88497625302?pwd=QnJVME5hTXhFTXE3RWVGNys5Ykpidz09">Live</a>  </strong>
            <li>PST 5:45am-6:30am; IST 3:45pm-4:30pm</li> 
            <p>Invited Talk: <strong>Ekin Dogus Cubuk - Adversarial examples of classifiers, physical systems, and beyond - <a href="https://go-live-il.zoom.us/j/88497625302?pwd=QnJVME5hTXhFTXE3RWVGNys5Ykpidz09">Live</a>  </strong>
            <li>PST 6:30am-7:00am; IST 4:30pm-5:00pm</li> 
            <p>Invited Talk: <strong>Bolei Zhou - Benchmarking AI Safety of Autonomous Driving through Diverse Traffic Scenario Generation - <a href="https://go-live-il.zoom.us/j/88497625302?pwd=QnJVME5hTXhFTXE3RWVGNys5Ykpidz09">Live</a>  </strong>
            <li>PST 7:00am-7:30am; IST 5:00pm-5:30pm</li> 
            <p>Invited Talk: <strong>Dan Hendrycks - Beyond the Lp Ball and Long Tails - <a href="https://go-live-il.zoom.us/j/88497625302?pwd=QnJVME5hTXhFTXE3RWVGNys5Ykpidz09">Live</a>  </strong>
                    
            <li>PST 7:30am-8:30am; IST 5:30pm-6:30pm </li> 
            <p><strong>Best Paper Session - <a href="https://go-live-il.zoom.us/j/88497625302?pwd=QnJVME5hTXhFTXE3RWVGNys5Ykpidz09">Live</a>  </strong>
        </div>
</div>

</br>


<div class="container">
    <h2>Best Paper Awards</h2>
        <div class="overview">
            <h3><p><strong>AROW Workshop Best Papers</font></strong></h3>
            <li><b> Physical Passive Patch Adversarial Attacks on Visual Odometry Systems </b> [<a href="short_paper/0004.pdf">Paper</a>] [<a href="short_paper/0004_supp.pdf">Supp</a>] <br> Yaniv Nemcovsky (Technion); Matan Jacoby (Technion); Alex  Bronstein (Tel Aviv University, Israel); Chaim Baskin (Technion)* </li>
            <li><b> FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning </b> [<a href="short_paper/0033.pdf">Paper</a>] <br> Kaiyuan Zhang (Purdue University)*; Guanhong Tao (Purdue University); Qiuling Xu (Purdue University); Siyuan Cheng (Purdue University); Shengwei An (Purdue University); Yingqi Liu (Purdue University); Shiwei Feng (Purdue University); Pin-Yu Chen (IBM Research); Shiqing Ma (Rutgers University); Xiangyu Zhang (Purdue University) </li>
                    
            <h3><p><strong>Best Papers</font></strong></h3>
            <li><b> ALA: Adversarial Lightness Attack via Naturalness-aware Regularizations </b> [<a href="short_paper/0003.pdf">Paper</a>] <br> Liangru Sun (East China Normal University)*; Felix Juefei-Xu (Meta AI); Yihao Huang (East China Normal University); Qing Guo (Nanyang Technological University); Jiayi Zhu (East China Normal University); Jincao Feng (East China Normal University); Yang Liu (Nanyang Technology University, Singapore); Geguang Pu (East China Normal University) </li>
            <li><b> Attacking Motion Estimation with Adversarial Snow </b> [<a href="short_paper/0014.pdf">Paper</a>] [<a href="short_paper/0014_supp.pdf">Supp</a>] <br> Jenny Schmalfuss (University of Stuttgart)*; Lukas Mehl (University of Stuttgart); Andrés Bruhn (University of Stuttgart) </li>
            <li><b> BadDet: Backdoor Attacks on Object Detection </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Shih-Han Chan (University of California San Diego)*; Yinpeng Dong (Tsinghua University); Jun Zhu (Tsinghua University); Xiaolu Zhang (Ant Financial Services Group); Jun Zhou (Ant Financial) </li>
                 
        </div>
</div>



</br>
<div class="container">
        <h2>Accepted Long Paper </h2>
        <div class="overview">
            <ul>
                <li><b> TransPatch: A Transformer-based Generator for Accelerating Transferable Patch Generation in Adversarial Attacks Against Object Detection Models </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Jinghao Wang (nanyang technological university)*; Chenling Cui (Nanyang Technological University); XUEJUN WEN (Huawei International Pte Ltd); Jie Shi (Huawei International) </li>
                <li><b> Feature-level augmentation to improve robustness of deep neural networks to affine transformations </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Adrian Sandru (SecurifAI); Mariana-Iuliana Georgescu (University of Bucharest); Radu Tudor Ionescu (University of Bucharest)* </li>
                <li><b> Benchmarking Robustness beyond $l_p$ Norm Adversaries </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Akshay Agarwal (University at Buffalo)*; Nalini Ratha (SUNY Buffalo); Mayank  Vatsa (IIT Jodhpur); Richa Singh (IIT Jodhpur) </li>
                <li><b> Masked Faces with Faced Masks </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Jiayi Zhu (East China Normal University)*; Qing Guo (Nanyang Technological University); Felix Juefei-Xu (Meta AI); Yihao Huang (East China Normal University); Yang Liu (Nanyang Technology University, Singapore); Geguang Pu (East China Normal University) </li>
                <li><b> Adversarially Robust Panoptic Segmentation (ARPaS) Benchmark </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Laura Daza (Universidad de los Andes)*; Jordi Pont-Tuset (Google); Pablo Arbelaez (Universidad de los Andes) </li>
                <li><b> BadDet: Backdoor Attacks on Object Detection </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Shih-Han Chan (University of California San Diego)*; Yinpeng Dong (Tsinghua University); Jun Zhu (Tsinghua University); Xiaolu Zhang (Ant Financial Services Group); Jun Zhou (Ant Financial) </li>
                <li><b> Universal, Transferable Adversarial Perturbations for Visual Object Trackers </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Krishna Kanth Nakka (EPFL)*; Mathieu Salzmann (EPFL) </li>
                <li><b> Fluctuation in video analytics - Why? Now what? </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] [<a href="https://youtu.be/oobyJoYijJs">Video</a>] <br> Sibendu Paul (Purdue University)*; Kunal Rao (NEC Labs); Giuseppe Coviello (NEC Labs); Murugan Sankaradas (NEC Labs); Oliver Po (NEC Labs); Y. Charlie Hu (Purdue University); Srimat Chakradhar (nec labs) </li>
                <li><b> SkeleVision: Towards Adversarial Resiliency of Person Tracking with Multi-Task Learning </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Nilaksh Das (Georgia Institute of Technology); ShengYun Peng (Georgia Institute of Technology)*; Duen Horng Chau (Georgia Institute of Technology) </li>
                <li><b> Unrestricted Black-box Adversarial Attack Using GAN with Limited Queries </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Dongbin Na (POSTECH)*; Sangwoo Ji (POSTECH); Jong Kim (POSTECH) </li>
                <li><b> Truth-Table Net: A New Convolutional Architecture Encodable By Design Into SAT Formulas </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Adrien Benamira (Nanyang Technological University)*; Thomas Peyrin (NTU); Bryan Hooi (NUS) </li>
                <li><b> Attribution-Based Confidence Metric for Detection of Adversarial Attacks on Breast Histopathological Images </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Steven Fernandes (Creighton University)*; Senka Krivic (University of Sarajevo); Poonam Sharma (Creighton University); Sumit K Jha (University of Texas at San Antonio) </li>
                <li><b> Improving Adversarial Robustness by Penalizing Natural Accuracy </b> [<a href="https://eccv22-arow.github.io/">Paper</a>] <br> Kshitij Chandna (New York University)* </li>
            </ul>
        </div>
</div>

<br>
<div class="container">
        <h2>Accepted Extended Abstract</h2>
        <div class="overview">
            <ul>
                <li><b> ALA: Adversarial Lightness Attack via Naturalness-aware Regularizations </b> [<a href="short_paper/0003.pdf">Paper</a>] <br> Liangru Sun (East China Normal University)*; Felix Juefei-Xu (Meta AI); Yihao Huang (East China Normal University); Qing Guo (Nanyang Technological University); Jiayi Zhu (East China Normal University); Jincao Feng (East China Normal University); Yang Liu (Nanyang Technology University, Singapore); Geguang Pu (East China Normal University) </li>
                <li><b> Physical Passive Patch Adversarial Attacks on Visual Odometry Systems </b> [<a href="short_paper/0004.pdf">Paper</a>] [<a href="short_paper/0004_supp.pdf">Supp</a>] <br> Yaniv Nemcovsky (Technion); Matan Jacoby (Technion); Alex  Bronstein (Tel Aviv University, Israel); Chaim Baskin (Technion)* </li>
                <li><b> Scaling Adversarial Training to Large Perturbation Bounds </b> [<a href="short_paper/0006.pdf">Paper</a>] [<a href="short_paper/0006_supp.pdf">Supp</a>] <br> Sravanti Addepalli (Indian Institute of Science)*; Samyak Jain (Indian Institute of Technology (BHU), Varanasi); Gaurang Sriramanan (University of Maryland, College Park); Venkatesh Babu RADHAKRISHNAN (Indian Institute of Science) </li>
                <li><b> Confidence-aware Training of Smoothed Classifiers for Certified Robustness </b> [<a href="short_paper/0007.pdf">Paper</a>] [<a href="short_paper/0007_supp.pdf">Supp</a>] <br> Jongheon Jeong (KAIST)*; Seojin Kim (KAIST); Jinwoo Shin (KAIST) </li>
                <li><b> Task Agnostic and Post-hoc Unseen Distribution Detection </b> [<a href="short_paper/0008.pdf">Paper</a>] <br> Radhika Dua (KAIST)*; Seongjun Yang (KAIST); Yixuan Li (University of Wisconsin-Madison); Edward Choi (KAIST) </li>
                <li><b> Empowering a Robust Model with Stable and Object-Aligned Explanations </b> [<a href="short_paper/0013.pdf">Paper</a>] <br> Sowrya Gali (Indian Institute of Technology, Hyderabad)*; Anindya Sarkar (Washington University in St. Louis); Vineeth N Balasubramanian (Indian Institute of Technology, Hyderabad) </li>
                <li><b> Attacking Motion Estimation with Adversarial Snow </b> [<a href="short_paper/0014.pdf">Paper</a>] [<a href="short_paper/0014_supp.pdf">Supp</a>] <br> Jenny Schmalfuss (University of Stuttgart)*; Lukas Mehl (University of Stuttgart); Andrés Bruhn (University of Stuttgart) </li>
                <li><b> Adversarial amplitude swap towards robust image classifiers </b> [<a href="short_paper/0015.pdf">Paper</a>] <br> Chun Yang Tan (Chiba University)*; Kazuhiko Kawamoto (Chiba University); Hiroshi Kera (Chiba University) </li>
                <li><b> How and When Adversarial Robustness Improves in Knowledge Distillation? </b> [<a href="short_paper/0020.pdf">Paper</a>] <br> Rulin Shao (Carmegie Mellon University); Jinfeng Yi (JD AI Research); Cho-Jui Hsieh (UCLA); Pin-Yu Chen (IBM Research)* </li>
                <li><b> Efficient Training Methods for Achieving Adversarial Robustness Against Sparse Attacks </b> [<a href="short_paper/0021.pdf">Paper</a>] [<a href="short_paper/0021_supp.pdf">Supp</a>] <br> Sravanti Addepalli (Indian Institute of Science)*; Dhruv Behl (Indian Institute of Science); Gaurang Sriramanan (University of Maryland, College Park); Venkatesh Babu RADHAKRISHNAN (Indian Institute of Science) </li>
                <li><b> The Hidden Costs on Distributional Shifts when Fine-tuning Joint Text-Image Encoders and Redemptions </b> [<a href="short_paper/0028.pdf">Paper</a>] [<a href="short_paper/0028_supp.pdf">Supp</a>] <br> Andrew Geng (IBM)*; Pin-Yu Chen (IBM Research) </li>
                <li><b> Adversarially Robust Few-shot Learning through Simple Transfer </b> [<a href="short_paper/0029.pdf">Paper</a>] [<a href="short_paper/0029_supp.pdf">Supp</a>] <br> Akshayvarun Subramanya (UMBC)*; Hamed Pirsiavash (University of California Davis) </li>
                <li><b> BARReL: Bottleneck Attention for Adversarial Robustness in Vision-Based Reinforcement Learning </b> [<a href="short_paper/0032.pdf">Paper</a>] <br> Eugene Bykovets (ETH Zürich)*; Yannick Metz (University of Konstanz);  Mennatallah  El-Assady (ETH AI Center ); Daniel Keim (Uni. Konstanz); Joachim  Buhmann (ETH Zurich) </li>
                <li><b> FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated Learning </b> [<a href="short_paper/0033.pdf">Paper</a>] <br> Kaiyuan Zhang (Purdue University)*; Guanhong Tao (Purdue University); Qiuling Xu (Purdue University); Siyuan Cheng (Purdue University); Shengwei An (Purdue University); Yingqi Liu (Purdue University); Shiwei Feng (Purdue University); Pin-Yu Chen (IBM Research); Shiqing Ma (Rutgers University); Xiangyu Zhang (Purdue University) </li>
                <li><b> Be Your Own Neighborhood: Detecting Adversarial Example by the Neighborhood Relations Built on Self-Supervised Learning </b> [<a href="short_paper/0035.pdf">Paper</a>] <br> Zhiyuan He (The Chinese University of Hong Kong)*; Yijun Yang (The Chinese University of Hong Kong); Pin-Yu Chen (IBM Research); Qiang Xu (The Chinese University of Hong Kong); Tsung-Yi Ho (The Chinese University of Hong Kong) </li>
                <li><b> Certified Defenses Against Near-Subspace Unrestricted Adversarial Attacks </b>  [<a href="short_paper/eccvw22.pdf">Paper</a>]  <br> Ambar Pal (Johns Hopkins University)*; Rene Vidal (Johns Hopkins University, USA) </li>
                <li><b> GREAT Score: Evaluating Global Adversarial Robustness using Generative Models </b> [<a href="short_paper/0040.pdf">Paper</a>] <br> ZAITANG LI (CUHK)*; Pin-Yu Chen (IBM Research); Tsung-Yi Ho (The Chinese University of Hong Kong) </li>
            </ul>
        </div>
</div>

<br>

<div class="container">
    <h2>Speakers</h2>
    <div>
        <div class="instructor">
            <a href="https://sites.google.com/site/pinyuchenpage/home">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/PinYuChen.png"></div>
                <div>Pin-Yu Chen<br>IBM</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://web.northeastern.edu/xuelin/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/XueLin.png"></div>
                <div>Xue Lin<br>Northeastern University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://boleizhou.github.io/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/BoleiZhou.png"></div>
                <div>Bolei Zhou<br>UCLA</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://people.eecs.berkeley.edu/~hendrycks/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/DanHendrycks.png"></div>
                <div>Dan Hendrycks<br>UC Berkeley</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://research.google/people/EkinDogusCubuk/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/EkinDogusCubuk.png"></div>
                <div>Ekin Dogus Cubuk<br>Google Brain</div>
            </a>
        </div>

    </div>

    <p></p>
        <div class="instructor">
            <a href="https://himalakkaraju.github.io/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/HimaLakkaraju.png"></div>
                <div>Hima Lakkaraju<br>Harvard University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.cs.princeton.edu/~olgarus/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/OlgaRussakovsky.png"></div>
                <div>Olga Russakovsky<br>Princeton University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://cihangxie.github.io/">
                <div class="instructorphoto"><img src="figures/cihangxie.jpg"></div>
                <div>Cihang Xie<br>UCSC</div>
            </a>
        </div>
    
        <div class="instructor">
            <a href="http://www.cs.jhu.edu/~ayuille/index.html">
                <div class="instructorphoto"><img src="figures/alanyuille.png"></div>
                <div>Alan Yuille<br>Johns Hopkins University</div>
            </a>
        </div>


</div>

<br>

<div class="container">
    <h2>Organizing Committee</h2>

    <div>
        <div class="instructor">
            <a href="https://scholar.google.com/citations?user=YR7re-cAAAAJ&hl">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/AngtianWang.png"></div>
                <div>Angtian Wang<br>Johns Hopkins University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://scholar.google.com/citations?user=N1-l4GsAAAAJ&hl=en">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/YutongBai.png"></div>
                <div>Yutong Bai<br>Johns Hopkins University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://adamkortylewski.com/">
                <div class="instructorphoto"><img src="figures/AdamKortylewski.png"></div>
                <div>Adam Kortylewski<br>Johns Hopkins University</div>
            </a>
        </div>
        <div class="instructor">
            <a href="https://cihangxie.github.io/">
                <div class="instructorphoto"><img src="figures/cihangxie.jpg"></div>
                <div>Cihang Xie<br>UCSC</div>
            </a>
        </div>


        <div class="instructor">
            <a href="https://jungyhuk.github.io/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/XinyunChen.png"></div>
                <div>Xinyun Chen<br>UCB</div>
            </a>
        </div>
    </div>


    <p></p>

    <div>

        <div class="instructor">
            <a href="https://yingwei.li">
                <div class="instructorphoto"><img src="figures/YingweiLi.jpg"></div>
                <div>Yingwei Li<br>Johns Hopkins University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://scholar.google.com/citations?user=V5NWZc8AAAAJ&hl=en">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/AlexanderRobey.png"></div>
                <div>Alexander Robey<br>UPenn</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://scholar.google.com/citations?user=v-JL-hsAAAAJ&hl=en">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/WielandBrendel.png"></div>
                <div>Wieland Brendel<br>University of Tübingen</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://ml.cs.tsinghua.edu.cn/~yinpeng/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/YinpengDong.png"></div>
                <div>Yinpeng Dong<br>Tsinghua University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://https://tacju.github.io/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/JuHe.png"></div>
                <div>Ju He<br>Johns Hopkins University</div>
            </a>
        </div>
    </div>
    <p></p>

    <div>
        <div class="instructor">
            <a href="https://scholar.google.com/citations?user=bvG0PeEAAAAJ&hl=en">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/SiyueWang.png"></div>
                <div>Siyue Wang<br>Northeastern University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://natanielruiz.github.io/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/NatanielRuiz.png"></div>
                <div>Nataniel Ruiz<br>Boston University</div>
            </a>
        </div>
        <div class="instructor">
            <a href="https://resvirtualis.github.io/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/PhilippeBurlina.png"></div>
                <div>Philippe Burlina<br>Johns Hopkins University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://ml.cs.tsinghua.edu.cn/~jun/index.shtml">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/JunZhu.png"></div>
                <div>Jun Zhu<br>Tsinghua University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://people.eecs.berkeley.edu/~dawnsong/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/DawnSong.png"></div>
                <div>Dawn Song<br>UCB</div>
            </a>
        </div>
    </div>

    <p></p>

    <div>
            
        <div class="instructor">
            <a href="https://engineering.jhu.edu/ece/faculty/rama-chellappa/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/RamaChellappa.png"></div>
                <div>Rama Chellappa<br>Johns Hopkins University</div>
            </a>
        </div>

    
        <div class="instructor">
            <a href="https://www.suhangss.me/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/HangSu.png"></div>
                <div>Hang Su<br>Tsinghua University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/maschinelles-lernen/team/prof-dr-matthias-hein/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/MatthiasHein.png"></div>
                <div>Matthias Hein<br>University of Tübingen</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://www.cc.gatech.edu/~judy/">
                <div class="instructorphoto"><img src="figures/2021_cropped_photos/JudyHoffman.png"></div>
                <div>Judy Hoffman<br>Georgia Tech</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://www.cs.jhu.edu/~ayuille/index.html">
                <div class="instructorphoto"><img src="figures/alanyuille.png"></div>
                <div>Alan Yuille<br>Johns Hopkins University</div>
            </a>
        </div>

    </div>

</div>

<br>

<div class="container">
    <h2>Program Committee</h2>
    <div class="pcs-row pcs">
       <div class="pcs-column">
           <ul>
            <li>Akshayvarun Subramanya (UMBC)</li>
            <li>Alexander Robey	(University of Pennsylvania)</li>
            <li>Cheng Xinwen (Shanghai JiaoTong University)</li>
            <li>Dingcheng Yang (Tsinghua University)</li>
            <li>Gaurang Sriramanan (UMD)</li>
            <li>Guofeng Zhang (UCLA)</li>
            <li>Hanxun Huang (The University of Melbourne)</li>
            <li>Jiachen Sun (University of Michigan)</li>
            <li>Jieru Mei (Johns Hopkins University)</li>
            <li>Junbo Li (UC Santa Cruz)</li>
            <li>Kibok Lee (Yonsei University)</li>
            <li>Lifeng Huang (SunYat-sen university)</li>
            <li>Maura Pintor (University of Cagliari)</li>
            <li>Nataniel Ruiz (Boston University)</li>
            <li>Pengliang Ji (Beihang University)</li>
            <li>Qihao Liu (Johns Hopkins University)</li>
            <li>Qing Jin (Northeastern University)</li>
            <li>Rajkumar Theagarajan (UC Riverside)</li>
            <li>Ruihao Gong (SenseTime)</li>
            <li>Salah GHAMIZI (University of Luxembourg)</li>
            <li>Shihao Zhao (The University of Hong Kong)</li>
           </ul>
        </div>
        <div class="pcs-column">
            <ul>
            <li>Shunchang liu (Beihang University)</li>
            <li>Shutong Wu (Shanghai Jiao Tong University)</li>
            <li>Sizhe Chen (Shanghai Jiao Tong University)</li>
            <li>Sravanti Addepalli (Indian Institute of Science)</li>
            <li>Tao Li (Shanghai Jiao Tong University)</li>
            <li>Tianlin Li (NTU)</li>
            <li>Wenxiao Wang (University of Maryland)</li>
            <li>Won Park (University of Michigan)</li>
            <li>Wufei Ma (Johns Hopkins University)</li>
            <li>Xiaoding Yuan (Johns Hopkins University)</li>
            <li>Xingjun Ma (Fudan University)</li>
            <li>Yige Li (Xidian University)</li>
            <li>Yue Wang (Ford Motor Company)</li>
            <li>Yulong Cao (University of Michigan)</li>
            <li>Zhehao Huang (Shanghai Jiao Tong University)</li>
            <li>Zhengyi Wang (Tsinghua University)</li>
            <li>Zhongkai Hao (Tsinghua University)</li>
            <li>Zhouxing Shi (UCLA)</li>
            <li>Zichao Li (UC Santa Cruz)</li>
            <li>Zihao Xiao (Johns Hopkins University)</li>
            <li>Zonglei Jing (Beihang University)</li>
            </ul>
        </div>
    </div>
</div> 

<br>

<div class="container">
    <h2>Sponsor</h2>
    <div>
        <a href="https://ftxfuturefund.org/"> <img width="350" src="figures/WeChat Image_20221123202012.png"> </a>
    </div>
</div>

<!--</br>-->
<br>
<div class="container">
    <h2>Related Workshops</h2>
    <p align="left"><a href="https://sites.google.com/view/udlworkshop2021/home">Uncertainty & Robustness in Deep Learning (Workshop at ICML 2021)</a></p>
    <p align="left"><a href="https://aisecure-workshop.github.io/aml-iclr2021/">Security and Safety in Machine Learning Systems (Workshop at ICLR 2021)</a></p>
    <p align="left"><a href="https://iclr2021generalization.github.io/">Generalization beyond the Training Distribution in Brains and Machines (Workshop at ICLR 2021)</a></p>
    <p align="left"><a href="https://advm-workshop-2021.github.io/">1st International Workshop on Adversarial Learning for Multimedia (Workshop at ACM Multimedia 2021)</a></p>
    <p align="left"><a href="https://aisecure-workshop.github.io/amlcvpr2021/">Workshop on Adversarial Machine Learning in Real-World Computer Vision Systems and Online Challenges (Workshop at CVPR 2021)</a></p>
</div>

</br>

<div class="containersmall">
    <p>Please contact <a href="mailto:angtianwang@jhu.edu">Angtian Wang</a> or <a href="ytongbai@gmail.com">Yutong Bai</a> if you have questions. The webpage template
        is by the courtesy of <a href="https://eccv20-adv-workshop.github.io/">ECCV 2020 Workshop on
            Adversarial Robustness in the Real World</a>. </p>
</div>

<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
